name: Auto Crawl ITviec Jobs

on:
  schedule:
    - cron: '0 1 * * *'  # ch·∫°y 8h s√°ng VN m·ªói ng√†y
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false  # ƒë·ªÉ tr√°nh xung ƒë·ªôt khi commit l·∫°i
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser
          python -m pip install --upgrade pip setuptools wheel
          pip install --break-system-packages undetected-chromedriver selenium pandas

      - name: Run crawler (headless)
        run: |
          echo "üöÄ Starting crawler..."
          python main.py
          echo "‚úÖ Crawl completed."

      - name: Upload result CSV as artifact
        uses: actions/upload-artifact@v4
        with:
          name: itviec_jobs_full
          path: itviec_jobs_full.csv

      - name: Commit and push CSV to repository
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"

          mv itviec_jobs_full.csv data_itviec_jobs.csv || true

          git add data_itviec_jobs.csv || true
          git commit -m "ü§ñ Update ITviec jobs data [$(date '+%Y-%m-%d %H:%M')]" || echo "No changes to commit"

          # ‚öôÔ∏è C·∫•u h√¨nh l·∫°i remote ƒë·ªÉ d√πng token x√°c th·ª±c
          git remote remove origin
          git remote add origin https://x-access-token:${GITHUB_TOKEN}@github.com/${REPO}.git

          git push origin HEAD:main
