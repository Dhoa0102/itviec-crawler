name: Auto Crawl ITviec Jobs

on:
  schedule:
    - cron: '0 1 * * *'  # ch·∫°y 8h s√°ng VN m·ªói ng√†y
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: true  # c·∫ßn true ƒë·ªÉ c√≥ quy·ªÅn push
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
          python -m pip install --upgrade pip setuptools wheel
          pip install --break-system-packages undetected-chromedriver selenium pandas

      - name: Run crawler (headless)
        run: |
          echo "üöÄ Starting crawler..."
          python main.py
          echo "‚úÖ Crawl completed."

      - name: Upload result CSV as artifact
        uses: actions/upload-artifact@v4
        with:
          name: itviec_jobs_full
          path: itviec_jobs_full.csv

      - name: Commit and push CSV to repository
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"

          # ‚úÖ K√©o b·∫£n m·ªõi nh·∫•t v·ªÅ ƒë·ªÉ tr√°nh xung ƒë·ªôt
          git pull origin main --rebase || true

          # ‚úÖ ƒê·ªïi t√™n file n·∫øu c·∫ßn
          mv itviec_jobs_full.csv data_itviec_jobs.csv || true

          git add data_itviec_jobs.csv || true
          git commit -m "ü§ñ Update ITviec jobs data [$(date '+%Y-%m-%d %H:%M')]" || echo "No changes to commit"

          # ‚öôÔ∏è D√πng token m·∫∑c ƒë·ªãnh ƒë·ªÉ push an to√†n
          git push https://x-access-token:${GITHUB_TOKEN}@github.com/${REPO}.git HEAD:main
