name: Auto Crawl ITviec Jobs

on:
  schedule:
    - cron: '0 1 * * *'  # cháº¡y 8h sÃ¡ng VN má»—i ngÃ y
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          persist-credentials: false  # Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t khi commit láº¡i
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser
          python -m pip install --upgrade pip setuptools wheel
          pip install --break-system-packages undetected-chromedriver selenium pandas

      - name: Run crawler (headless)
        run: |
          echo "ðŸš€ Starting crawler..."
          python main.py
          echo "âœ… Crawl completed."

      - name: Upload result CSV as artifact
        uses: actions/upload-artifact@v4
        with:
          name: itviec_jobs_full
          path: itviec_jobs_full.csv

      # ðŸ§© ThÃªm bÆ°á»›c nÃ y Ä‘á»ƒ commit CSV má»›i vÃ o repo
      - name: Commit and push CSV to repository
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"

          # copy file ra thÆ° má»¥c gá»‘c náº¿u cáº§n
          mv itviec_jobs_full.csv data_itviec_jobs.csv

          git add data_itviec_jobs.csv
          git commit -m "ðŸ¤– Update ITviec jobs data [$(date '+%Y-%m-%d %H:%M')]"
          git push origin HEAD:main
